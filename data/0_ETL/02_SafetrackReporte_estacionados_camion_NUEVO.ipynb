{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =====================================\n",
    "# BLOQUE 1: Imports y Config\n",
    "# ====================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "from datetime import datetime\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Configuración de Directorio, Patrón y Listado de Archivos\n",
    "\n",
    "# Directorio donde se encuentran los archivos\n",
    "DIRECTORIO_SAFETRACK = \"../Safetrack\"\n",
    "\n",
    "# Patrón de regex para coincidir con los nombres de archivos esperados\n",
    "PATRON_ARCHIVO = r\"Reporte de viaje\\((\\d{8})-(\\d{8})\\)\\.xlsx$\"\n",
    "\n",
    "# Mapeo de números de mes a nombres en español\n",
    "MESES_ES = [\n",
    "    'Enero', 'Febrero', 'Marzo', 'Abril', 'Mayo', 'Junio',\n",
    "    'Julio', 'Agosto', 'Septiembre', 'Octubre', 'Noviembre', 'Diciembre'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =====================================\n",
    "# BLOQUE 2: Función de Logging\n",
    "# ====================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_proceso(df_antes, df_despues, etapa):\n",
    "  eliminados = len(df_antes) - len(df_despues)\n",
    "  porcentaje = (eliminados / len(df_antes)) * 100 if len(df_antes) > 0 else 0\n",
    "  print(f\"\\n=== Etapa: {etapa} ===\")\n",
    "  print(f\"Registros antes: {len(df_antes)}\")\n",
    "  print(f\"Registros después: {len(df_despues)}\")\n",
    "  print(f\"Registros eliminados: {eliminados} ({porcentaje:.2f}%)\")\n",
    "\n",
    "  if eliminados > 0:\n",
    "      registros_eliminados = df_antes[~df_antes.index.isin(df_despues.index)]\n",
    "      # Guardar registros eliminados en un archivo\n",
    "      archivo_eliminados = f\"../Limpia/eliminados_{etapa.lower().replace(' ', '_')}.xlsx\"\n",
    "      registros_eliminados.to_excel(archivo_eliminados, index=False)\n",
    "      print(f\"Registros eliminados guardados en: {archivo_eliminados}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =====================================\n",
    "# BLOQUE 3: Generar listas de archivos\n",
    "# ====================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos a procesar:\n",
      " - ../Safetrack\\Reporte de viaje(20241101-20241130).xlsx\n",
      " - ../Safetrack\\Reporte de viaje(20241201-20241231).xlsx\n",
      " - ../Safetrack\\Reporte de viaje(20250101-20250131).xlsx\n",
      " - ../Safetrack\\Reporte de viaje(20250201-20250217).xlsx\n",
      "\n",
      "Meses extraídos:\n",
      " - Noviembre\n",
      " - Diciembre\n",
      " - Enero\n",
      " - Febrero\n"
     ]
    }
   ],
   "source": [
    "def listar_archivos(directorio, patron):\n",
    "    archivos_coincidentes = []\n",
    "    for archivo in os.listdir(directorio):\n",
    "        if re.match(patron, archivo):\n",
    "            ruta_completa = os.path.join(directorio, archivo)\n",
    "            archivos_coincidentes.append(ruta_completa)\n",
    "    return archivos_coincidentes\n",
    "\n",
    "def generar_listas(directorio):\n",
    "    archivos = listar_archivos(directorio, PATRON_ARCHIVO)\n",
    "    archivos.sort(key=lambda x: datetime.strptime(re.match(PATRON_ARCHIVO, os.path.basename(x)).group(1), '%Y%m%d'))\n",
    "    meses = []\n",
    "    for arch in archivos:\n",
    "        match = re.match(PATRON_ARCHIVO, os.path.basename(arch))\n",
    "        fecha_inicio_str = match.group(1)\n",
    "        fecha_inicio = datetime.strptime(fecha_inicio_str, '%Y%m%d')\n",
    "        meses.append(MESES_ES[fecha_inicio.month - 1])\n",
    "    return archivos, meses\n",
    "\n",
    "archivos, meses = generar_listas(DIRECTORIO_SAFETRACK)\n",
    "print(\"Archivos a procesar:\")\n",
    "for arch in archivos:\n",
    "    print(f\" - {arch}\")\n",
    "print(\"\\nMeses extraídos:\")\n",
    "for mes in meses:\n",
    "    print(f\" - {mes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =====================================\n",
    "# BLOQUE 4: Funciones Auxiliares\n",
    "# ====================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalizacion**\n",
    "- normalize_str: Elimina tildes, pasa a minúsculas y quita espacios extremos\n",
    "- normalize_column: Normaliza nombres de columnas según un diccionario especial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Normalización ---\n",
    "def normalize_str(s):\n",
    "    s2 = unicodedata.normalize('NFKD', s).encode('ascii','ignore').decode('ascii')\n",
    "    return s2.lower().strip()\n",
    "\n",
    "def normalize_column(col):\n",
    "    special_columns = {\n",
    "        'Indice': 'Indice',\n",
    "        'Numero_de_placa': 'Numero_de_placa',\n",
    "        'Estado_de_viaje': 'Estado_de_viaje',\n",
    "        'Tiempo_de_Inicio': 'Tiempo_de_Inicio',\n",
    "        'Tiempo_Final': 'Tiempo_Final',\n",
    "        'Duracion': 'Duracion',\n",
    "        'Lugar_de_inicio': 'Lugar_de_inicio',\n",
    "        'LATITUD': 'LATITUD',\n",
    "        'LONGITUD': 'LONGITUD',\n",
    "        'camion_y': 'camion_y',\n",
    "        'camion_x': 'camion_x'\n",
    "    }\n",
    "    col_normalized = unicodedata.normalize('NFKD', col).encode('ASCII','ignore').decode('ASCII').strip()\n",
    "    if col in special_columns:\n",
    "        return special_columns[col]\n",
    "    for key in special_columns:\n",
    "        if col_normalized.lower() == key.lower():\n",
    "            return special_columns[key]\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conversión de duración** \n",
    "- convertir_a_decimal: Convierte una duración en formato 'XdYhZMinutosWs' a minutos decimales.\n",
    "- Ejemplo: '1d2h30Minutos45s' => (1*24*60)+(2*60)+30+45/60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Conversión de Duración ---\n",
    "def convertir_a_decimal(duracion):\n",
    "    try:\n",
    "        if not isinstance(duracion, str):\n",
    "            duracion = str(duracion)\n",
    "        dias = 0\n",
    "        total_min = 0\n",
    "        if 'd' in duracion:\n",
    "            partes = duracion.split('d')\n",
    "            dias = int(partes[0])\n",
    "            resto = partes[1]\n",
    "        else:\n",
    "            resto = duracion\n",
    "        total_min = dias * 24 * 60\n",
    "        pattern = r'(?:(\\d+)h)?(?:(\\d+)Minutos)?(?:(\\d+)s)?'\n",
    "        match = re.match(pattern, resto)\n",
    "        if match:\n",
    "            h = int(match.group(1)) if match.group(1) else 0\n",
    "            m = int(match.group(2)) if match.group(2) else 0\n",
    "            s = int(match.group(3)) if match.group(3) else 0\n",
    "            total_min += h * 60 + m + s / 60\n",
    "        else:\n",
    "            return None\n",
    "        return round(total_min, 2)\n",
    "    except Exception as e:\n",
    "        print(f\"Error en convertir_a_decimal({duracion}): {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Procesamiento de Coordenadas**:\n",
    "- convertir_coordenada: Convierte una cadena de coordenada, ej. '34.766437S' o '58.1234N',\n",
    "    a float. \n",
    "- split_coords: Separa latitud y longitud de un string 'LAT, LON'.\n",
    "    Retorna un pd.Series con [lat, lon] convertidos a float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertir_coordenada(coord_str):\n",
    "    if not isinstance(coord_str, str):\n",
    "        return None\n",
    "    c = coord_str.strip().upper()\n",
    "    if not c:\n",
    "        return None\n",
    "    sign = 1\n",
    "    if c[-1] in ['S','W']:\n",
    "        sign = -1\n",
    "        c = c[:-1]\n",
    "    elif c[-1] in ['N','E']:\n",
    "        c = c[:-1]\n",
    "    try:\n",
    "        return sign * float(c)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def split_coords(coord_str):\n",
    "    if not isinstance(coord_str, str):\n",
    "        return pd.Series([None, None])\n",
    "    parts = coord_str.split(',')\n",
    "    if len(parts) != 2:\n",
    "        return pd.Series([None, None])\n",
    "    lat_str, lon_str = parts[0].strip(), parts[1].strip()\n",
    "    lat = convertir_coordenada(lat_str)\n",
    "    lon = convertir_coordenada(lon_str)\n",
    "    return pd.Series([lat, lon])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mapeo de Placas**:\n",
    "- Aplica un diccionario de mapeo a la columna 'Numero_de_placa'.\n",
    "- Normaliza quitando espacios y pasando a mayúsculas antes de mapear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Mapeo de Placas ---\n",
    "def mapear_placas(df, mapeo):\n",
    "    if 'Numero_de_placa' not in df.columns:\n",
    "        print(\"No existe 'Numero_de_placa' en el DataFrame; se omite mapeo.\")\n",
    "        return df\n",
    "    df['Numero_de_placa_normalizada'] = df['Numero_de_placa'].str.replace(' ', '').str.upper()\n",
    "    print(\"Placas únicas antes del mapeo:\", sorted(df['Numero_de_placa_normalizada'].unique()))\n",
    "    print(\"Mapeo disponible:\", mapeo)\n",
    "    mapeo_normalizado = {k.upper(): v for k, v in mapeo.items()}\n",
    "    df['Numero_de_placa'] = df['Numero_de_placa_normalizada'].map(mapeo_normalizado).fillna(df['Numero_de_placa'])\n",
    "    df.drop(columns=['Numero_de_placa_normalizada'], inplace=True)\n",
    "    print(\"Placas únicas después del mapeo:\", sorted(df['Numero_de_placa'].unique()))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parseo de Archivos Excel**:\n",
    "-  Lee un archivo Excel sin encabezado fijo y detecta bloques de datos.\n",
    "-  Retorna un DataFrame unificado con columnas:\n",
    "   -  ['Indice', 'Numero_de_placa', 'Estado_de_viaje', 'Tiempo_de_Inicio',\n",
    "     'Tiempo_Final', 'Kilometraje_km', 'Duracion', 'Lugar_de_inicio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_report_file(path):\n",
    "    import os\n",
    "    print(f\"Parseando archivo: {os.path.basename(path)}\")\n",
    "    try:\n",
    "        df_raw = pd.read_excel(path, header=None, engine='openpyxl')\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error al leer el archivo {path}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "    df_norm = df_raw.copy()\n",
    "    for col_idx in df_norm.columns:\n",
    "        df_norm[col_idx] = df_norm[col_idx].astype(str).apply(normalize_str)\n",
    "    start_rows = []\n",
    "    for i in range(len(df_norm)):\n",
    "        row_text = \" \".join(df_norm.loc[i].tolist()).strip()\n",
    "        if '#' in row_text and 'numero' in row_text and 'placa' in row_text:\n",
    "            start_rows.append(i)\n",
    "    print(f\"Filas de encabezado detectadas: {start_rows}\")\n",
    "    if not start_rows:\n",
    "        print(\"No se detectaron filas de encabezado. Retornando DataFrame vacío.\")\n",
    "        return pd.DataFrame()\n",
    "    fin_regex_list = [\n",
    "        r'dispositivo\\s*:',\n",
    "        r'fecha\\s*:',\n",
    "        r'odometro\\s*:',\n",
    "        r'recuento\\s*de',\n",
    "        r'duraci.n\\s+del',\n",
    "        r'sin\\s+datos'\n",
    "    ]\n",
    "    fin_regex = \"|\".join(fin_regex_list)\n",
    "    all_blocks = []\n",
    "    for idx in range(len(start_rows)):\n",
    "        header_row = start_rows[idx]\n",
    "        data_start = header_row + 1\n",
    "        next_header = start_rows[idx+1] if idx < len(start_rows)-1 else len(df_norm)\n",
    "        data_end = None\n",
    "        for row_i in range(data_start, next_header):\n",
    "            row_text = \" \".join(df_norm.loc[row_i].tolist()).strip()\n",
    "            if re.search(fin_regex, row_text, flags=re.IGNORECASE):\n",
    "                data_end = row_i\n",
    "                break\n",
    "        if not data_end:\n",
    "            data_end = next_header\n",
    "        if data_end > data_start:\n",
    "            df_block = df_raw.iloc[data_start:data_end].copy().reset_index(drop=True)\n",
    "            if df_block.shape[1] < 9:\n",
    "                print(f\"Bloque ignorado (filas {data_start}:{data_end}) por tener menos de 9 columnas.\")\n",
    "                continue\n",
    "            df_block = df_block.iloc[:, :9]\n",
    "            df_block.columns = [\n",
    "                \"Indice\", \"Numero_de_placa\", \"Estado_de_viaje\",\n",
    "                \"Tiempo_de_Inicio\", \"Tiempo_Final\", \"Kilometraje_km\",\n",
    "                \"Duracion\", \"Lugar_de_inicio\", \"Fin_Localizacion\"\n",
    "            ]\n",
    "            df_block['Tiempo_de_Inicio'] = pd.to_datetime(df_block['Tiempo_de_Inicio'], errors='coerce')\n",
    "            df_block['Tiempo_Final'] = pd.to_datetime(df_block['Tiempo_Final'], errors='coerce')\n",
    "            df_block[['camion_x', 'camion_y']] = df_block['Lugar_de_inicio'].apply(lambda x: split_coords(x))\n",
    "            df_block.drop(columns=['Fin_Localizacion', 'Kilometraje_km'], inplace=True, errors='ignore')\n",
    "            all_blocks.append(df_block)\n",
    "            print(f\"Bloque {idx+1}: filas {data_start} a {data_end}, shape={df_block.shape}\")\n",
    "    if not all_blocks:\n",
    "        print(\"No se obtuvo ningún bloque válido. Retornando DataFrame vacío.\")\n",
    "        return pd.DataFrame()\n",
    "    df_final = pd.concat(all_blocks, ignore_index=True)\n",
    "    print(f\"Parseo final: {len(df_final)} filas obtenidas de {len(all_blocks)} bloques.\")\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limpieza global** aplica una serie de pasos de limpieza al DataFrame:\n",
    "* Elimina filas con 'Dispositivo:' o 'Fecha:'.\n",
    "*  Normaliza nombres de columnas.\n",
    "*  Renombra 'numero_de_placa_del_vehiculo' a 'Numero_de_placa' si es necesario.\n",
    "*  Aplica mapeo de placas.\n",
    "*  Convierte 'Duracion' a minutos decimales.\n",
    "*  Filtra registros con 'Tiempo_de_Inicio' entre 07:00 y 18:00."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Limpieza Global ---\n",
    "def limpieza_global(df, map_placas_dict):\n",
    "    total_inicial = len(df)\n",
    "    print(\"=== LIMPIEZA GLOBAL INICIADA ===\")\n",
    "    print(f\"Registros iniciales: {total_inicial}\")\n",
    "    if df.empty:\n",
    "        print(\"DataFrame vacío, no se realiza limpieza.\")\n",
    "        return df\n",
    " \n",
    "    cols_originales = df.columns.tolist()\n",
    "    df.columns = [normalize_column(c) for c in df.columns]\n",
    "    df = df[[col for col in df.columns if col is not None]]\n",
    "    print(\"Columnas antes:\", cols_originales)\n",
    "    print(\"Columnas después:\", df.columns.tolist())\n",
    "    if 'numero_de_placa_del_vehiculo' in df.columns and 'Numero_de_placa' not in df.columns:\n",
    "        df.rename(columns={'numero_de_placa_del_vehiculo': 'Numero_de_placa'}, inplace=True)\n",
    "        print(\"Renombrada 'numero_de_placa_del_vehiculo' a 'Numero_de_placa'\")\n",
    "    df = mapear_placas(df, map_placas_dict)\n",
    "    if 'Duracion' in df.columns:\n",
    "        df['Duracion'] = df['Duracion'].apply(convertir_a_decimal)\n",
    "        nulos = df['Duracion'].isnull().sum()\n",
    "        df.dropna(subset=['Duracion'], inplace=True)\n",
    "        print(f\"Convertir duración: eliminados {nulos} registros por valor nulo\")\n",
    "    else:\n",
    "        print(\"No existe columna 'Duracion'; se omite conversión\")\n",
    "    if 'Tiempo_de_Inicio' in df.columns:\n",
    "        df['Tiempo_de_Inicio'] = pd.to_datetime(df['Tiempo_de_Inicio'], errors='coerce')\n",
    "        nulos = df['Tiempo_de_Inicio'].isnull().sum()\n",
    "        if nulos:\n",
    "            df.dropna(subset=['Tiempo_de_Inicio'], inplace=True)\n",
    "            print(f\"Eliminados {nulos} registros con 'Tiempo_de_Inicio' nulo\")\n",
    "        mask_horario = (df['Tiempo_de_Inicio'].dt.hour >= 7) & (df['Tiempo_de_Inicio'].dt.hour < 18)\n",
    "        df = df[mask_horario]\n",
    "        print(f\"Filtrado horario: registros que cumplen la condición: {len(df)}\")\n",
    "    else:\n",
    "        print(\"No existe 'Tiempo_de_Inicio'; omitiendo filtro horario\")\n",
    "    print(\"=== LIMPIEZA GLOBAL COMPLETADA ===\")\n",
    "    print(f\"Registros finales: {len(df)}\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =====================================\n",
    "# BLOQUE 5: Procesamiento y Creación df_unificado\n",
    "# ====================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando archivo: ../Safetrack\\Reporte de viaje(20241101-20241130).xlsx\n",
      "Parseando archivo: Reporte de viaje(20241101-20241130).xlsx\n",
      "Filas de encabezado detectadas: [3, 1729, 2109, 3083, 4201]\n",
      "Bloque 1: filas 4 a 1722, shape=(1718, 9)\n",
      "Bloque 2: filas 1730 a 2102, shape=(372, 9)\n",
      "Bloque 3: filas 2110 a 3076, shape=(966, 9)\n",
      "Bloque 4: filas 3084 a 4194, shape=(1110, 9)\n",
      "Bloque 5: filas 4202 a 4870, shape=(668, 9)\n",
      "Parseo final: 4834 filas obtenidas de 5 bloques.\n",
      "Procesando archivo: ../Safetrack\\Reporte de viaje(20241201-20241231).xlsx\n",
      "Parseando archivo: Reporte de viaje(20241201-20241231).xlsx\n",
      "Filas de encabezado detectadas: [3, 1501, 2561, 3559, 4769]\n",
      "Bloque 1: filas 4 a 1494, shape=(1490, 9)\n",
      "Bloque 2: filas 1502 a 2554, shape=(1052, 9)\n",
      "Bloque 3: filas 2562 a 3552, shape=(990, 9)\n",
      "Bloque 4: filas 3560 a 4762, shape=(1202, 9)\n",
      "Parseo final: 4734 filas obtenidas de 4 bloques.\n",
      "Procesando archivo: ../Safetrack\\Reporte de viaje(20250101-20250131).xlsx\n",
      "Parseando archivo: Reporte de viaje(20250101-20250131).xlsx\n",
      "Filas de encabezado detectadas: [3, 1741, 2887, 3819, 4905]\n",
      "Bloque 1: filas 4 a 1734, shape=(1730, 9)\n",
      "Bloque 2: filas 1742 a 2880, shape=(1138, 9)\n",
      "Bloque 3: filas 2888 a 3812, shape=(924, 9)\n",
      "Bloque 4: filas 3820 a 4898, shape=(1078, 9)\n",
      "Parseo final: 4870 filas obtenidas de 4 bloques.\n",
      "Procesando archivo: ../Safetrack\\Reporte de viaje(20250201-20250217).xlsx\n",
      "Parseando archivo: Reporte de viaje(20250201-20250217).xlsx\n",
      "Filas de encabezado detectadas: [3, 889, 1449, 1977, 2527]\n",
      "Bloque 1: filas 4 a 882, shape=(878, 9)\n",
      "Bloque 2: filas 890 a 1442, shape=(552, 9)\n",
      "Bloque 3: filas 1450 a 1970, shape=(520, 9)\n",
      "Bloque 4: filas 1978 a 2520, shape=(542, 9)\n",
      "Parseo final: 2492 filas obtenidas de 4 bloques.\n",
      "Total registros unificados: 16930\n"
     ]
    }
   ],
   "source": [
    "lista_df = []\n",
    "for archivo in archivos:\n",
    "    print(f\"Procesando archivo: {archivo}\")\n",
    "    df_temp = parse_report_file(archivo)\n",
    "    if not df_temp.empty:\n",
    "        lista_df.append(df_temp)\n",
    "    else:\n",
    "        print(f\"Archivo {archivo} no produjo datos válidos.\")\n",
    "\n",
    "if lista_df:\n",
    "    df_unificado = pd.concat(lista_df, ignore_index=True)\n",
    "    print(f\"Total registros unificados: {len(df_unificado)}\")\n",
    "else:\n",
    "    print(\"No se obtuvieron registros de ningún archivo.\")\n",
    "    df_unificado = pd.DataFrame()  # df_unificado vacío si no hay nada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =====================================\n",
    "# BLOQUE 6: Filtrar por Estacionamiento (Opcional) y Limpieza\n",
    "# ====================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros 'Estacionamiento': 8465\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Filtrado por 'Estacionamiento' y Limpieza Global ---\n",
    "df_estacionamiento = df_unificado[df_unificado[\"Estado_de_viaje\"].isin([\"Estacionamiento\"])].copy()\n",
    "print(f\"Registros 'Estacionamiento': {len(df_estacionamiento)}\")\n",
    "\n",
    "# PLACAS A REEMPLAZAR\n",
    "MAP_PLACAS = {\n",
    "    'CAA 1076': 'BYD1004',\n",
    "    'Wireless-16956': 'PartnerABG9758',\n",
    "    'AAW 4251': 'PARTNER 4251'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicamos la limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LIMPIEZA GLOBAL INICIADA ===\n",
      "Registros iniciales: 8465\n",
      "Columnas antes: ['Indice', 'Numero_de_placa', 'Estado_de_viaje', 'Tiempo_de_Inicio', 'Tiempo_Final', 'Duracion', 'Lugar_de_inicio', 'camion_x', 'camion_y']\n",
      "Columnas después: ['Indice', 'Numero_de_placa', 'Estado_de_viaje', 'Tiempo_de_Inicio', 'Tiempo_Final', 'Duracion', 'Lugar_de_inicio', 'camion_x', 'camion_y']\n",
      "Placas únicas antes del mapeo: ['AAW4251', 'BYD1006', 'CAA1076', 'PEUGEOTAVG9758', 'WIRELESS-16956']\n",
      "Mapeo disponible: {'CAA 1076': 'BYD1004', 'Wireless-16956': 'PartnerABG9758', 'AAW 4251': 'PARTNER 4251'}\n",
      "Placas únicas después del mapeo: ['AAW 4251', 'BYD1006', 'CAA 1076', 'PartnerABG9758', 'Peugeot AVG9758']\n",
      "Convertir duración: eliminados 0 registros por valor nulo\n",
      "Filtrado horario: registros que cumplen la condición: 7943\n",
      "=== LIMPIEZA GLOBAL COMPLETADA ===\n",
      "Registros finales: 7943\n"
     ]
    }
   ],
   "source": [
    "df_limpio = limpieza_global(df_estacionamiento, MAP_PLACAS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =====================================\n",
    "# BLOQUE 7: Guardado de Resultados\n",
    "# ====================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo 'estacionados_camion.xlsx' guardado en ../Limpia\n"
     ]
    }
   ],
   "source": [
    "if not df_limpio.empty:\n",
    "    estacionados_camion = df_limpio.copy()\n",
    "    estacionados_camion.to_excel(\"../Limpia/estacionados_camion.xlsx\", index=False)\n",
    "    print(\"Archivo 'estacionados_camion.xlsx' guardado en ../Limpia\")\n",
    "else:\n",
    "    print(\"El DataFrame final está vacío, no se genera archivo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ====================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7943 entries, 1 to 16929\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   Indice            7943 non-null   object        \n",
      " 1   Numero_de_placa   7943 non-null   object        \n",
      " 2   Estado_de_viaje   7943 non-null   object        \n",
      " 3   Tiempo_de_Inicio  7943 non-null   datetime64[ns]\n",
      " 4   Tiempo_Final      7943 non-null   datetime64[ns]\n",
      " 5   Duracion          7943 non-null   float64       \n",
      " 6   Lugar_de_inicio   7943 non-null   object        \n",
      " 7   camion_x          7943 non-null   float64       \n",
      " 8   camion_y          7943 non-null   float64       \n",
      "dtypes: datetime64[ns](2), float64(3), object(4)\n",
      "memory usage: 620.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Indice</th>\n",
       "      <th>Numero_de_placa</th>\n",
       "      <th>Estado_de_viaje</th>\n",
       "      <th>Tiempo_de_Inicio</th>\n",
       "      <th>Tiempo_Final</th>\n",
       "      <th>Duracion</th>\n",
       "      <th>Lugar_de_inicio</th>\n",
       "      <th>camion_x</th>\n",
       "      <th>camion_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>AAW 4251</td>\n",
       "      <td>Estacionamiento</td>\n",
       "      <td>2024-11-01 08:16:42</td>\n",
       "      <td>2024-11-01 08:24:59</td>\n",
       "      <td>8.28</td>\n",
       "      <td>34.773337S,55.739224W</td>\n",
       "      <td>-34.773337</td>\n",
       "      <td>-55.739224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>AAW 4251</td>\n",
       "      <td>Estacionamiento</td>\n",
       "      <td>2024-11-01 08:29:39</td>\n",
       "      <td>2024-11-01 08:37:30</td>\n",
       "      <td>7.85</td>\n",
       "      <td>34.770112S,55.762495W</td>\n",
       "      <td>-34.770112</td>\n",
       "      <td>-55.762495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Indice Numero_de_placa  Estado_de_viaje    Tiempo_de_Inicio  \\\n",
       "1      2        AAW 4251  Estacionamiento 2024-11-01 08:16:42   \n",
       "3      4        AAW 4251  Estacionamiento 2024-11-01 08:29:39   \n",
       "\n",
       "         Tiempo_Final  Duracion        Lugar_de_inicio   camion_x   camion_y  \n",
       "1 2024-11-01 08:24:59      8.28  34.773337S,55.739224W -34.773337 -55.739224  \n",
       "3 2024-11-01 08:37:30      7.85  34.770112S,55.762495W -34.770112 -55.762495  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_limpio.info()\n",
    "df_limpio.head(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
